{"version":3,"file":"component---src-pages-experiments-ghost-slotting-mdx-22e6bb3ec96d89af028a.js","mappings":"8KAIA,SAASA,EAAkBC,GACzB,MAAMC,EAAcC,OAAOC,OAAO,CAChCC,GAAI,KACJC,EAAG,IACHC,KAAM,OACNC,EAAG,MACFC,EAAAA,EAAAA,KAAsBR,EAAMS,YAC/B,OAAOC,EAAAA,cAAoBA,EAAAA,SAAgB,KAAMA,EAAAA,cAAoBT,EAAYG,GAAI,CACnFO,GAAI,iBACJC,MAAO,CACLC,SAAU,aAEXH,EAAAA,cAAoBT,EAAYI,EAAG,CACpCS,KAAM,kBACN,aAAc,2BACdC,UAAW,iBACVL,EAAAA,cAAoBT,EAAYK,KAAM,CACvCU,wBAAyB,CACvBC,OAAQ,meAEP,kBAAmB,KAAM,KAAMP,EAAAA,cAAoBQ,EAAAA,EAAO,CAC7DC,IAAK,qBACH,KAAMT,EAAAA,cAAoBT,EAAYM,EAAG,KAAM,iCAAkCG,EAAAA,cAAoBT,EAAYI,EAAG,CACtHS,KAAM,uCACL,WAAY,0CAA2C,KAAMJ,EAAAA,cAAoBT,EAAYM,EAAG,KAAM,2NAA6N,KAAMG,EAAAA,cAAoBT,EAAYM,EAAG,KAAM,2TAA6T,KAAMG,EAAAA,cAAoBT,EAAYM,EAAG,KAAM,sPAA2P,KAAMG,EAAAA,cAAoBT,EAAYM,EAAG,KAAM,oLAAqL,KAAMG,EAAAA,cAAoBT,EAAYM,EAAG,KAAM,oQACjvC,CAKA,UAJA,SAAoBP,QAAK,IAALA,IAAAA,EAAQ,CAAC,GAC3B,MAAOoB,QAASC,GAAanB,OAAOC,OAAO,CAAC,GAAGK,EAAAA,EAAAA,KAAsBR,EAAMS,YAC3E,OAAOY,EAAYX,EAAAA,cAAoBW,EAAWrB,EAAOU,EAAAA,cAAoBX,EAAmBC,IAAUD,EAAkBC,EAC9H,C,qEChCe,SAASkB,EAAKI,GAA4B,IAA3B,IAAEH,GAAsBG,EACpD,OACEZ,EAAAA,cAAA,SACEa,UAAQ,EACRX,MAAO,CACLY,aAAc,OACdC,MAAO,OACPC,OAAQ,OACRC,UAAW,OACXC,aAAc,SAGhBlB,EAAAA,cAAA,UAAQS,IAAG,IAAMA,EAAOU,KAAK,cAAc,+CAIjD,C","sources":["webpack://gatsby-starter-default/./src/pages/experiments/ghost-slotting.mdx","webpack://gatsby-starter-default/./src/components/video.tsx"],"sourcesContent":["/*@jsxRuntime classic @jsx React.createElement @jsxFrag React.Fragment*/\nimport {useMDXComponents as _provideComponents} from \"@mdx-js/react\";\nimport React from \"react\";\nimport Video from \"../../components/video\";\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    h1: \"h1\",\n    a: \"a\",\n    span: \"span\",\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return React.createElement(React.Fragment, null, React.createElement(_components.h1, {\n    id: \"ghost-slotting\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#ghost-slotting\",\n    \"aria-label\": \"ghost slotting permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Ghost Slotting\"), \"\\n\", \"\\n\", React.createElement(Video, {\n    src: \"videos/ghost.mp4\"\n  }), \"\\n\", React.createElement(_components.p, null, \"What does autocompletion a la \", React.createElement(_components.a, {\n    href: \"https://github.com/features/copilot\"\n  }, \"Copilot\"), \" look like in a spatial design canvas?\"), \"\\n\", React.createElement(_components.p, null, \"A naive interpretation would resemble Copilot's \\\"typeahead\\\" interaction, surfacing a whole hypothetical design on top of the very same canvas, then accept it en masse. This seemed distracting and unintuitive to me.\"), \"\\n\", React.createElement(_components.p, null, \"When designing, I have specific \\\"regions of interest\\\" on the canvas at any given moment. I might be designing a list item, having drawn the container and planning to populate it with content. I would want to communicate my future intentions to a copilot spatially, mousing over regions I'd like it to populate.\"), \"\\n\", React.createElement(_components.p, null, \"I built a proto-design tool in which completions only appeared when activating a \\\"completion mode\\\". The shapes generated appear subtly as \\\"ghost-slots\\\", which you can mouse over in regions of interest to preview and commit them to the design.\"), \"\\n\", React.createElement(_components.p, null, \"These slots unobtrusively layer on top of the canvas. They communicate regions of potential intent, but don't presume the content underneath until the user confirms the intent.\"), \"\\n\", React.createElement(_components.p, null, \"The system used GPT-4, which performed impressively on spatial reasoning with a coordinate-based encoding of the design, but was rather slow to generate. I suspect that a specialized, faster model could supplement a significant fraction of my design edits.\"));\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? React.createElement(MDXLayout, props, React.createElement(_createMdxContent, props)) : _createMdxContent(props);\n}\nexport default MDXContent;\n","import React from \"react\"\nexport default function Video({ src }: { src: string }) {\n  return (\n    <video\n      controls\n      style={{\n        borderRadius: \"10px\",\n        width: \"100%\",\n        height: \"auto\",\n        marginTop: \"10px\",\n        marginBottom: \"40px\",\n      }}\n    >\n      <source src={`/${src}`} type=\"video/mp4\" />\n      Your browser does not support the video tag.\n    </video>\n  )\n}\n"],"names":["_createMdxContent","props","_components","Object","assign","h1","a","span","p","_provideComponents","components","React","id","style","position","href","className","dangerouslySetInnerHTML","__html","Video","src","wrapper","MDXLayout","_ref","controls","borderRadius","width","height","marginTop","marginBottom","type"],"sourceRoot":""}